- 驱动层

  - epoll 驱动层跟 poll 一样，区别在与其内核层和用户层

- 用户层

```c
#include <stdio.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/epoll.h>
#include <sys/ioctl.h>

int main()
{
    int fd = open("/dev/epoll_demo", O_RDONLY | O_NONBLOCK);
    if (fd < 0) {
        perror("open");
        return -1;
    }

    int epfd = epoll_create1(0);

    struct epoll_event ev;
    ev.events = EPOLLIN;
    ev.data.fd = fd;

    epoll_ctl(epfd, EPOLL_CTL_ADD, fd, &ev);

    printf("wait for event...\n");

    while (1) {
        struct epoll_event events[1];
        int nfds = epoll_wait(epfd, events, 1, -1);

        if (nfds > 0) {
            printf("epoll notified\n");

            char buf[8];
            int ret = read(fd, buf, sizeof(buf));
            printf("read ret = %d, char=%c\n", ret, buf[0]);
        }
    }

    close(epfd);
    close(fd);
    return 0;
}
```

- 内核层

  - poll 每次对所有 fd 进行一次扫描（调用 poll），核心代码在 do_poll 本质就是一个大的 for 循环
    - static int do_poll(struct poll_list *list, struct poll_wqueues *wait, struct timespec64 \*end_time)
  - epoll

    - 当调用 epoll_ctl(EPOLL_CTL_ADD)时，会注册回调函数，把就绪事件放到 epoll 的 ready-list

      ```c
      SYSCALL_DEFINE4(epoll_ctl, int, epfd, int, op, int, fd, struct epoll_event __user *, event) {
      	......
      	switch (op) {
      		case EPOLL_CTL_ADD:
      			if (!epi) {
      				epds.events |= EPOLLERR | EPOLLHUP;
      				error = ep_insert(ep, &epds, tf.file, fd, full_check);
      			} else
      				error = -EEXIST;
      			if (full_check)
      				clear_tfile_check_list();
      			break;
      	}
      }
      static int ep_insert(struct eventpoll *ep, const struct epoll_event *event,
         struct file *tfile, int fd, int full_check)
      {
      	......
      	struct ep_pqueue epq;
      	struct epitem *epi;
      	epq.epi = epi;
      	ep_set_ffd(&epi->ffd, tfile, fd)
      	init_poll_funcptr(&epq.pt, ep_ptable_queue_proc);
      }
      static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead,
      	 poll_table *pt)
      {
      	struct epitem *epi = ep_item_from_epqueue(pt);
      	struct eppoll_entry *pwq;

      	if (epi->nwait >= 0 && (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) {
      		init_waitqueue_func_entry(&pwq->wait, ep_poll_callback);
      		pwq->whead = whead;
      		pwq->base = epi;
      		if (epi->event.events & EPOLLEXCLUSIVE)
      			add_wait_queue_exclusive(whead, &pwq->wait);
      		else
      			add_wait_queue(whead, &pwq->wait);
      		list_add_tail(&pwq->llink, &epi->pwqlist);
      		epi->nwait++;
      	} else {
      		/* We have to signal that an error occurred */
      		epi->nwait = -1;
      	}
      }
      ```

    * epoll_wait 直接从 ready-list 拷贝返回（避免每次遍历大量 fd）


static __poll_t ep_item_poll(const struct epitem *epi, poll_table *pt,
				 int depth)
{
	struct eventpoll *ep;
	bool locked;

	pt->_key = epi->event.events;
	if (!is_file_epoll(epi->ffd.file))
		return vfs_poll(epi->ffd.file, pt) & epi->event.events;

	ep = epi->ffd.file->private_data;
	poll_wait(epi->ffd.file, &ep->poll_wait, pt);
	locked = pt && (pt->_qproc == ep_ptable_queue_proc);

	return ep_scan_ready_list(epi->ffd.file->private_data,
				  ep_read_events_proc, &depth, depth,
				  locked) & epi->event.events;
}